{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23d0284",
   "metadata": {},
   "source": [
    "## Algoritmos de Machine Learning\n",
    "\n",
    "Un **algoritmo de Machine Learning** es un conjunto de reglas matem√°ticas que permiten a un modelo aprender patrones a partir de datos. Se pueden dividir en varias categor√≠as:\n",
    "\n",
    "### üìå **Tipos de Algoritmos:**\n",
    "\n",
    "1. **Aprendizaje Supervisado** (con etiquetas):\n",
    "   - Regresi√≥n Lineal\n",
    "   - Regresi√≥n Log√≠stica\n",
    "   - √Årboles de Decisi√≥n\n",
    "   - M√°quinas de Soporte Vectorial (SVM)\n",
    "   - Redes Neuronales\n",
    "\n",
    "2. **Aprendizaje No Supervisado** (sin etiquetas):\n",
    "   - Clustering (K-Means, DBSCAN, etc.)\n",
    "   - An√°lisis de Componentes Principales (PCA)\n",
    "\n",
    "3. **Aprendizaje por Refuerzo**\n",
    "   - Q-Learning\n",
    "   - Deep Q-Networks (DQN)\n",
    "   - El aprendizaje por refuerzo (Reinforcement Learning, RL) es un tipo de Machine Learning donde un agente aprende a tomar decisiones mediante prueba y error, recibiendo recompensas o penalizaciones seg√∫n sus acciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e03fa3",
   "metadata": {},
   "source": [
    "## Modelos de Clasificaci√≥n\n",
    "\n",
    "Los modelos de **Clasificaci√≥n** son un tipo de aprendizaje supervisado que asignan una etiqueta a cada entrada. Algunos modelos de clasificaci√≥n comunes incluyen:\n",
    "\n",
    "### üè∑ **Modelos de Clasificaci√≥n Binaria**\n",
    "- **Regresi√≥n Log√≠stica** ‚Üí Predice dos clases (ejemplo: spam o no spam).\n",
    "- **√Årbol de Decisi√≥n** ‚Üí Divide los datos en nodos de decisi√≥n.\n",
    "- **M√°quinas de Soporte Vectorial (SVM)** ‚Üí Encuentra un hiperplano √≥ptimo para separar clases.\n",
    "\n",
    "### üè∑ **Modelos de Clasificaci√≥n Multiclase**\n",
    "- **K-Vecinos M√°s Cercanos (KNN)** ‚Üí Clasifica basado en los vecinos m√°s cercanos.\n",
    "- **Redes Neuronales** ‚Üí Modelos complejos que aprenden patrones en los datos.\n",
    "\n",
    "### üìä **Ejemplo Visual de Clasificaci√≥n con SVM**\n",
    "![Clasificaci√≥n SVM](https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/SVM_margin.png/640px-SVM_margin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2928ae8",
   "metadata": {},
   "source": [
    "## Decision Boundary\n",
    "- Un Decision Boundary es una l√≠nea o margen que separa las clases.\n",
    "- El algoritmo de clasificaci√≥n trata de encontrar el l√≠mite de decisi√≥n que ayude a distinguir entre las clases de manera perfecta o casi perfecta.\n",
    "- La regresi√≥n log√≠stica decide un ajuste adecuado al l√≠mite de decisi√≥n para que podamos predecir a qu√© clase corresponder√° un nuevo dato.\n",
    "\n",
    "![Aprendizaje Supervisado](https://miro.medium.com/v2/resize:fit:720/format:webp/1*kmMho6PkiVbOXKEYvguMOQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879020d1",
   "metadata": {},
   "source": [
    "## Aprendizaje Supervisado\n",
    "\n",
    "El **Aprendizaje Supervisado** es una t√©cnica de Machine Learning en la que un modelo aprende a partir de ejemplos etiquetados.\n",
    "\n",
    "### üìå **Ejemplo de Aprendizaje Supervisado**\n",
    "- Entrenamos un modelo con im√°genes de **gatos** y **perros**.\n",
    "- Etiquetamos las im√°genes como ‚Äúgato‚Äù o ‚Äúperro‚Äù.\n",
    "- El modelo aprende a predecir la categor√≠a de nuevas im√°genes.\n",
    "\n",
    "![Aprendizaje Supervisado](https://miro.medium.com/v2/resize:fit:720/format:webp/1*3FgpptTWzpd2RLgKbV-HvA.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d7209",
   "metadata": {},
   "source": [
    "## Fundamentos Matem√°ticos de la Regresi√≥n Log√≠stica\n",
    "\n",
    "La **regresi√≥n log√≠stica** es un modelo estad√≠stico que se utiliza para predecir una variable de respuesta binaria (0 o 1) a partir de una o m√°s variables independientes \\( X \\). A diferencia de la regresi√≥n lineal, la regresi√≥n log√≠stica usa la funci√≥n sigmoide para modelar la probabilidad de pertenencia a una de las clases.\n",
    "\n",
    "El modelo se expresa como:\n",
    "\n",
    "$$ P(y=1 | X) = \\sigma(\\theta^T X) = \\frac{1}{1 + e^{-\\theta^T X}} $$\n",
    "\n",
    "Donde:\n",
    "- \\( y \\) es la variable dependiente binaria.\n",
    "- \\( X \\) es la matriz de caracter√≠sticas.\n",
    "- \\( theta \\) son los par√°metros del modelo.\n",
    "- \\( sigma \\) es la funci√≥n sigmoide.\n",
    "\n",
    "El objetivo es encontrar los valores √≥ptimos de \\( theta \\) que maximicen la probabilidad de clasificaci√≥n correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b445211",
   "metadata": {},
   "source": [
    "### Funci√≥n Sigmoide\n",
    "\n",
    "La **funci√≥n sigmoide** es utilizada en la regresi√≥n log√≠stica para modelar la probabilidad de pertenencia a una clase. Convierte cualquier valor real en un valor en el rango \\( (0,1) \\), lo que lo hace ideal para problemas de clasificaci√≥n binaria.\n",
    "\n",
    "Se define como:\n",
    "\n",
    "$$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "\n",
    "Donde\n",
    "\n",
    "$$ z = X \\theta $$\n",
    "\n",
    "En nuestro modelo, la funci√≥n sigmoide toma como entrada la multiplicaci√≥n matricial entre las caracter√≠sticas (x) y los coeficientes (theta):\n",
    "\n",
    "$$ \\sigma(X \\theta) = \\frac{1}{1 + e^{-X \\theta}} $$\n",
    "![Funci√≥n Sigmoide](https://miro.medium.com/v2/resize:fit:640/format:webp/1*xTwaKZZsIRek8jzrNWRPzQ.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f92ac6",
   "metadata": {},
   "source": [
    "## Funci√≥n de Costo en Regresi√≥n Log√≠stica\n",
    "\n",
    "La funci√≥n de costo es una funci√≥n que mide el rendimiento de un modelo de aprendizaje autom√°tico para datos determinados.\n",
    "\n",
    "La funci√≥n de costo es b√°sicamente el c√°lculo del error entre los valores predichos y los valores esperados y lo presenta en forma de un √∫nico n√∫mero real.\n",
    "\n",
    "Mucha gente confunde la funci√≥n de costo con la funci√≥n de p√©rdida.\n",
    "\n",
    "Bueno, para decirlo en t√©rminos simples, la **funci√≥n de costo** es el promedio del error de n muestras en los datos y la **funci√≥n de p√©rdida** es el error de puntos de datos individuales. En otras palabras, la funci√≥n de p√©rdida es para un ejemplo de entrenamiento, la funci√≥n de costo es para todo el conjunto de entrenamiento.\n",
    "\n",
    "Profundiza: https://medium.com/analytics-vidhya/understanding-logistic-regression-b3c672deac04\n",
    "\n",
    "Para entrenar el modelo, utilizamos la funci√≥n de **log-verosimilitud**, que mide qu√© tan bien los par√°metros explican los datos:\n",
    "\n",
    "$$ \\ell(\\theta) = \\sum_{i=1}^{n} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right] $$\n",
    "\n",
    "Sin embargo, en la pr√°ctica se minimiza la versi√≥n negativa de esta funci√≥n, conocida como **log-loss** o **binary cross-entropy**:\n",
    "\n",
    "$$ J(\\theta) = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right] $$\n",
    "\n",
    "**Minimizar** esta funci√≥n equivale a encontrar los par√°metros √≥ptimos para el modelo log√≠stico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6cf6f",
   "metadata": {},
   "source": [
    "### Regularizaci√≥n en Regresi√≥n Log√≠stica\n",
    "\n",
    "Para evitar sobreajuste, a√±adimos un **t√©rmino de regularizaci√≥n** a la funci√≥n de costo. El m√©todo m√°s com√∫n es la **regularizaci√≥n L2 (Ridge)**, que penaliza grandes valores en los coeficientes:\n",
    "\n",
    "$$ R(\\theta) = \\frac{\\lambda}{2n} \\sum_{j=1}^{m} \\theta_j^2 $$\n",
    "\n",
    "Incorporando la regularizaci√≥n en la funci√≥n de costo:\n",
    "\n",
    "$$ J(\\theta) = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log \\sigma(X_i \\theta) + (1 - y_i) \\log (1 - \\sigma(X_i \\theta)) \\right] + \\frac{\\lambda}{2n} \\sum_{j=1}^{m} \\theta_j^2 $$\n",
    "\n",
    "Donde \\( lambda \\) es el hiperpar√°metro que controla la intensidad de la regularizaci√≥n.\n",
    "\n",
    "Tambien puedes obtener el costo y la regularizaci√≥n aparte y sumarlos (te dejo el c√≥digo prellenado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4dc1ef",
   "metadata": {},
   "source": [
    "### Actividad. Diagn√≥stico de afecciones en tejido mamario.\n",
    "- Realiza las instrucciones propuestas en las celdas markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv('data.csv')\n",
    "df.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b2785",
   "metadata": {},
   "source": [
    "#### Obten los datos de entrada y de salida\n",
    "- Elimina las columnas innecesarias 'id', 'Unnamed: 32'\n",
    "- Convierte variable objetivo o dependiente \"diagn√≥stico\" a num√©rico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17600ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de datos\n",
    "df = df.drop(<Llena c√≥digo faltante>)  # Eliminar columnas irrelevantes\n",
    "df['diagnosis'] = df['diagnosis'].map(<Llena c√≥digo faltante>)  # Convertir variable objetivo o dependiente \"diagn√≥stico\" a num√©rico\n",
    "# Obten X e y\n",
    "X = df.drop(columns=['diagnosis']).values\n",
    "y = df['diagnosis'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7b00a2",
   "metadata": {},
   "source": [
    "#### Separa los datos en conjuntos X_train, X_test, y_train, y_test para su estudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82afea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n del conjunto de datos\n",
    "X_train, X_test, y_train, y_test = <Llena c√≥digo faltante>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fad2f77",
   "metadata": {},
   "source": [
    "#### Estandariza los datos con StandarScaler\n",
    "La **estandarizaci√≥n** es un proceso de transformaci√≥n de datos en el que cada caracter√≠stica del conjunto de datos se ajusta para que tenga **media cero** y **varianza unitaria**. Esto es especialmente √∫til para algoritmos de aprendizaje autom√°tico que utilizan optimizaci√≥n basada en gradientes, como la **Regresi√≥n Log√≠stica**.\n",
    "\n",
    "Dado un conjunto de datos con caracter√≠sticas \\( X \\), cada valor \\( x_i \\) se transforma seg√∫n la siguiente ecuaci√≥n:\n",
    "\n",
    "$$\n",
    "x_{\\text{estandarizado}} = \\frac{x_i - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- (mu) es la **media** de la caracter√≠stica.\n",
    "- (sigma) es la **desviaci√≥n est√°ndar** de la caracter√≠stica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f981da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.<Llena c√≥digo faltante>\n",
    "X_test_scaled = scaler.<Llena c√≥digo faltante>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d133d9",
   "metadata": {},
   "source": [
    "#### Define las funciones matem√°ticas del modelo\n",
    "- Define la funci√≥n sigmoide\n",
    "- Define la funci√≥n de regularizaci√≥n\n",
    "- Define la funci√≥n de costo. Retorna costo + regularizaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecc770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la funci√≥n sigmoide con entrada X @ theta\n",
    "def sigmoid(z):\n",
    "    return <Llena c√≥digo faltante>\n",
    "\n",
    "# Definir la funci√≥n de regularizaci√≥n L2\n",
    "def regularization(theta, lambda_reg, m):\n",
    "    return <Llena c√≥digo faltante>  # Omite theta_0\n",
    "\n",
    "# Definir la funci√≥n de costo con regularizaci√≥n\n",
    "def cost_function_reg(theta, X, y, lambda_reg=0.1):\n",
    "    m = len(y)\n",
    "    h = sigmoid(<Llena c√≥digo faltante, aplica una multiplicaci√≥n de matrices>)\n",
    "    epsilon = 1e-5  # Para evitar log(0)\n",
    "    cost = <Llena c√≥digo faltante>\n",
    "    return cost + regularization(theta, lambda_reg, m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0ca78",
   "metadata": {},
   "source": [
    "#### Obten los coeficientes de la regresi√≥n logistica\n",
    "- En los datos X de entrenamiento, agrega una columna de unos al principio. \n",
    "    - Esto es un requisito de la funci√≥n minimize y sirve para el t√©rmino de sesgo en los datos de entrenamiento.\n",
    "- Crea un vector de ceros 'theta_init' con la dimensi√≥n del n√∫mero total de columnas de X de entrenamiento\n",
    "- Realiza la optimizaci√≥n con scipy.minimize y obten los coeficientes de la regresi√≥n logistica.\n",
    "    - Utiliza el m√©todo de BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0693437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar columna de unos para el t√©rmino de sesgo en los datos de entrenamiento\n",
    "X_train_bias_scaled = np.c_[np.ones((X_train_scaled.shape[0], 1)), X_train_scaled]\n",
    "theta_init = np.zeros(X_train_bias_scaled.shape[1])\n",
    "\n",
    "# Optimizaci√≥n con scipy\n",
    "res = <Llena c√≥digo faltante>\n",
    "theta_opt_scaled = res.x\n",
    "\n",
    "print('Coeficientes obtenidos con scipy:', theta_opt_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b68bb",
   "metadata": {},
   "source": [
    "### Eval√∫a la efectividad del modelo\n",
    "- En los datos X de prueba, agrega una columna de unos al principio. \n",
    "    - Esto para que tenga la misma dimensi√≥n que theta_opt_scaled y lo pueda procesar.\n",
    "- Utiliza la funci√≥n sigmoide y los coeficientes de la regresi√≥n log√≠stica para obtener las predicciones\n",
    "- Escala los datos con un umbral de 0.5 y guardalos en un vector  'y_pred_scaled'\n",
    "-   Esto significa que si son mayores o iguales a 0.5, la salida es 1. Si son menores, la salida es 0.\n",
    "- Muestra el vector  'y_pred_scaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7225eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar la efectividad del modelo optimizado con scipy en los datos normalizados\n",
    "X_test_bias_scaled = <Llena c√≥digo faltante>\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred_prob_scaled = <Llena c√≥digo faltante, recuerda usar multiplicaci√≥n de matrices>\n",
    "y_pred_scaled = <Llena c√≥digo faltante>\n",
    "y_pred_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baced2d",
   "metadata": {},
   "source": [
    "#### Eval√∫a el accuracy del modelo. \n",
    "##### ¬øQu√© es el Accuracy?\n",
    "El **accuracy** (precisi√≥n) es una m√©trica fundamental en Machine Learning que mide el porcentaje de predicciones correctas sobre el total de predicciones realizadas.\n",
    "\n",
    "Se define como:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{N√∫mero de predicciones correctas}}{\\text{N√∫mero total de predicciones}}\n",
    "$$\n",
    "\n",
    "o en t√©rminos de clasificaci√≥n binaria:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- **TP (True Positives)**: Casos positivos correctamente clasificados.\n",
    "- **TN (True Negatives)**: Casos negativos correctamente clasificados.\n",
    "- **FP (False Positives)**: Casos negativos incorrectamente clasificados como positivos.\n",
    "- **FN (False Negatives)**: Casos positivos incorrectamente clasificados como negativos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37589888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular precisi√≥n del modelo optimizado con scipy en datos normalizados\n",
    "accuracy_scipy_scaled = <Llena c√≥digo faltante>\n",
    "\n",
    "print('Precisi√≥n del modelo con scipy:', accuracy_scipy_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f7bd9",
   "metadata": {},
   "source": [
    "### Actividad: Implementa la soluci√≥n en Sklearn y compara los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06568994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Comprueba tus resultados con la implementaci√≥n en sklearn. \n",
    "# Importar la regresi√≥n log√≠stica de scikit-learn\n",
    "<Llena c√≥digo faltante>\n",
    "\n",
    "# Crear y entrenar el modelo de regresi√≥n log√≠stica con scikit-learn\n",
    "<Llena c√≥digo faltante>\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "<Llena c√≥digo faltante>\n",
    "\n",
    "# Calcular la precisi√≥n del modelo con scikit-learn\n",
    "accuracy_sklearn = <Llena c√≥digo faltante>\n",
    "\n",
    "# Mostrar resultados\n",
    "accuracy_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ae7d1c",
   "metadata": {},
   "source": [
    "### Realiza tu conclusiones.\n",
    "El accuracy tiene que ser el mismo o casi el mismo en la implementaci√≥n manual o utilizando la librer√≠a de sklearn.\n",
    "\n",
    "¬øLograste el objetivo?\n",
    "\n",
    "¬øQu√© fue lo m√°s dificil para ti en esta actividad?\n",
    "\n",
    "¬øQu√© fue lo que m√°s te gust√≥?\n",
    "\n",
    "¬øCon qu√© te quedas de esta actividad?\n",
    "\n",
    "¬øEn tus propias palabras qu√© es el accuracy?\n",
    "\n",
    "¬øPodr√≠as decirme cuantos Ciertos positivos tuvo tu modelo?\n",
    "\n",
    "¬øEn el caso de los datos de este estudio qu√© te importa m√°s, los Ciertos postivos, los ciertos falsos, los falsos positivos o los falsos negativos?\n",
    "\n",
    "¬øPara qu√© te sirve la regularizaci√≥n?\n",
    "\n",
    "Investiga en internet en qu√© afecta el sobreajuste a los modelos de clasificaci√≥n. Describe con pocas palabras ¬øPor qu√© es bueno evitar el sobreajuste?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
